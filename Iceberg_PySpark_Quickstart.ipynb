{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "private-diversity",
   "metadata": {},
   "source": [
    "# Using Apache Iceberg with Spark 3 in CML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-silly",
   "metadata": {},
   "source": [
    "The official documentation for Apache Iceberg with Spark is located at [this link](https://iceberg.apache.org/#getting-started/#using-iceberg-in-spark-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-burns",
   "metadata": {},
   "source": [
    "For a full list of Apache Iceberg terms, please visit [this link](https://iceberg.apache.org/#terms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3071c73f-9846-435b-847a-f6799335b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"DROP TABLE IF EXISTS spark_catalog.testdb.newtesttable\")\n",
    "#spark.sql(\"DROP TABLE IF EXISTS spark_catalog.testdb.secondtesttable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf2b3c40-49d1-4f0f-879d-a28cd3d27aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-committee",
   "metadata": {},
   "source": [
    "### Start a PySpark Session as shown below. You will want to set the Spark Catalog configurations as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "incomplete-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SimpleApp.py\"\"\"\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "  .appName(\"1.1 - Ingest\") \\\n",
    "  .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\", \"us-east-2\")\\\n",
    "  .config(\"spark.yarn.access.hadoopFileSystems\", \"s3a://demo-aws-go02\")\\\n",
    "  .config(\"spark.jars\",\"/home/cdsw/lib/iceberg-spark3-runtime-0.9.1.1.13.317211.0-9.jar\") \\\n",
    "  .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.local\",\"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.local.type\",\"hadoop\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog.type\",\"hive\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-level",
   "metadata": {},
   "source": [
    "### Iceberg comes with catalogs that enable SQL commands to manage tables and load them by name. \n",
    "### Catalogs are configured using properties under spark.sql.catalog.(catalog_name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "prompt-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|   testdb|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # Using a local Spark Catalog\n",
    "\n",
    "#spark.sql(\"CREATE DATABASE IF NOT EXISTS spark_catalog.newjar\")\n",
    "spark.sql(\"USE spark_catalog.testdb\")\n",
    "spark.sql(\"SHOW CURRENT NAMESPACE\").show()\n",
    "#spark.sql(\"DROP TABLE testtable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-immune",
   "metadata": {},
   "source": [
    "### You can use simple Spark SQL commands to create Spark tables as you always have. Just make sure to specify the USING iceberg clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "extended-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS newtesttable (id bigint, data string) USING iceberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-pickup",
   "metadata": {},
   "source": [
    "### To select a specific table snapshot or the snapshot at some time, Iceberg supports two Spark read options:\n",
    "\n",
    "* snapshot-id selects a specific table snapshot\n",
    "* as-of-timestamp selects the current snapshot at a timestamp, in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-definition",
   "metadata": {},
   "source": [
    "#### You can view all snapshots associated with the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17ec587b-605f-4a1c-9d42-292d02ed1b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, data: string]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM spark_catalog.testdb.newtesttable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "future-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                                              |summary                                                                                                                                                                                                                                                                                                       |\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2022-05-19 00:27:36.444|5797822168349485877|null               |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-5797822168349485877-1-03061e1e-f684-4d48-99ef-a0a44f5b3fb0.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 2, added-records -> 3, added-files-size -> 1244, changed-partition-count -> 1, total-records -> 3, total-files-size -> 1244, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2022-05-19 00:28:16.897|3326689113563627160|5797822168349485877|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-3326689113563627160-1-ba8ef600-1765-4b6e-8295-440f1ed19db0.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 2, added-records -> 3, added-files-size -> 1244, changed-partition-count -> 1, total-records -> 6, total-files-size -> 2488, total-data-files -> 4, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2022-05-19 00:36:41.604|2080039523045202901|3326689113563627160|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-2080039523045202901-1-b9da32db-7fe7-4742-964e-7668ac5edebc.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 7, total-files-size -> 3110, total-data-files -> 5, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2022-05-19 00:36:42.87 |8726800525946754873|2080039523045202901|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-8726800525946754873-1-4262de11-21b9-44d5-b920-3020697c3ae0.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 8, total-files-size -> 3732, total-data-files -> 6, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2022-05-19 00:36:43.934|5250560437891035012|8726800525946754873|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-5250560437891035012-1-9c28ea48-7ac1-4211-b4ea-b7ec054570af.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 9, total-files-size -> 4354, total-data-files -> 7, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2022-05-19 00:36:44.966|3502850421386520639|5250560437891035012|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-3502850421386520639-1-2cba0459-7eb1-4c88-bfc7-6cab5b00afc8.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 10, total-files-size -> 4976, total-data-files -> 8, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2022-05-19 00:36:46.076|6484488418513084975|3502850421386520639|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-6484488418513084975-1-48e7ea2d-09c1-4510-9636-c00a125113e5.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 11, total-files-size -> 5598, total-data-files -> 9, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2022-05-19 00:36:47.109|6131843803655349628|6484488418513084975|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-6131843803655349628-1-f98692e9-e835-47b9-9dd7-8dd95ba8c1d4.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 12, total-files-size -> 6220, total-data-files -> 10, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:48.125|9149412625213001646|6131843803655349628|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-9149412625213001646-1-fc3ab2a3-c676-4156-80e9-60f444fe8440.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 13, total-files-size -> 6842, total-data-files -> 11, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:49.154|7899258739660324236|9149412625213001646|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-7899258739660324236-1-35178f9e-d36f-4c8e-87f0-43aef8981f95.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 14, total-files-size -> 7464, total-data-files -> 12, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:50.275|3534193066800053318|7899258739660324236|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-3534193066800053318-1-a6d41404-7850-4bb4-9968-dbbea26f69d6.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 15, total-files-size -> 8086, total-data-files -> 13, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:51.352|1934686370749576161|3534193066800053318|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-1934686370749576161-1-88afb9a7-3172-4f8a-9c6b-ff3f503720b5.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 16, total-files-size -> 8708, total-data-files -> 14, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:52.394|5426517119305366496|1934686370749576161|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-5426517119305366496-1-0d343ec4-03d6-4f35-89a2-4dc7c4e22ff7.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 17, total-files-size -> 9330, total-data-files -> 15, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:53.462|373037863119265479 |5426517119305366496|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-373037863119265479-1-fec1ac7a-21bf-443b-8982-2530b28daff4.avro |{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 18, total-files-size -> 9952, total-data-files -> 16, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-05-19 00:36:54.518|5758957638750915040|373037863119265479 |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-5758957638750915040-1-cd7c35a3-9568-4116-9217-ebe06b4fb058.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 621, changed-partition-count -> 1, total-records -> 19, total-files-size -> 10573, total-data-files -> 17, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-05-19 00:36:55.545|8456174629502915114|5758957638750915040|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-8456174629502915114-1-f1bc3096-05a0-4941-9173-9bc9469b5014.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 20, total-files-size -> 11195, total-data-files -> 18, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-05-19 00:36:56.526|919494437088828330 |8456174629502915114|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-919494437088828330-1-3aa628a5-c9d6-45db-bafb-2097f1fc5816.avro |{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 21, total-files-size -> 11817, total-data-files -> 19, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-05-19 00:36:57.604|8941097323185820492|919494437088828330 |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-8941097323185820492-1-211c40dd-47cf-4e31-aa5c-b649bcdb8911.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 22, total-files-size -> 12439, total-data-files -> 20, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-05-19 00:36:58.628|6624958993800383470|8941097323185820492|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-6624958993800383470-1-8d7e56a1-1b66-4a99-8760-a62676cecf30.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 23, total-files-size -> 13061, total-data-files -> 21, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-05-19 00:36:59.632|8215457020905462961|6624958993800383470|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/snap-8215457020905462961-1-40995ae2-9480-4055-9d4f-ef13ba4dd628.avro|{spark.app.id -> spark-application-1652919800484, added-data-files -> 1, added-records -> 1, added-files-size -> 622, changed-partition-count -> 1, total-records -> 24, total-files-size -> 13683, total-data-files -> 22, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "+-----------------------+-------------------+-------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable.snapshots\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-place",
   "metadata": {},
   "source": [
    "#### Or a full table version history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adequate-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2022-05-19 00:27:36.444|5797822168349485877|null               |true               |\n",
      "|2022-05-19 00:28:16.897|3326689113563627160|5797822168349485877|true               |\n",
      "|2022-05-19 00:36:41.604|2080039523045202901|3326689113563627160|true               |\n",
      "|2022-05-19 00:36:42.87 |8726800525946754873|2080039523045202901|true               |\n",
      "|2022-05-19 00:36:43.934|5250560437891035012|8726800525946754873|true               |\n",
      "|2022-05-19 00:36:44.966|3502850421386520639|5250560437891035012|true               |\n",
      "|2022-05-19 00:36:46.076|6484488418513084975|3502850421386520639|true               |\n",
      "|2022-05-19 00:36:47.109|6131843803655349628|6484488418513084975|true               |\n",
      "|2022-05-19 00:36:48.125|9149412625213001646|6131843803655349628|true               |\n",
      "|2022-05-19 00:36:49.154|7899258739660324236|9149412625213001646|true               |\n",
      "|2022-05-19 00:36:50.275|3534193066800053318|7899258739660324236|true               |\n",
      "|2022-05-19 00:36:51.352|1934686370749576161|3534193066800053318|true               |\n",
      "|2022-05-19 00:36:52.394|5426517119305366496|1934686370749576161|true               |\n",
      "|2022-05-19 00:36:53.462|373037863119265479 |5426517119305366496|true               |\n",
      "|2022-05-19 00:36:54.518|5758957638750915040|373037863119265479 |true               |\n",
      "|2022-05-19 00:36:55.545|8456174629502915114|5758957638750915040|true               |\n",
      "|2022-05-19 00:36:56.526|919494437088828330 |8456174629502915114|true               |\n",
      "|2022-05-19 00:36:57.604|8941097323185820492|919494437088828330 |true               |\n",
      "|2022-05-19 00:36:58.628|6624958993800383470|8941097323185820492|true               |\n",
      "|2022-05-19 00:36:59.632|8215457020905462961|6624958993800383470|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable.history\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-active",
   "metadata": {},
   "source": [
    "#### To show a table’s data files and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "excessive-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "|content|file_path                                                                                                                                     |file_format|record_count|file_size_in_bytes|column_sizes      |value_counts    |null_value_counts|nan_value_counts|lower_bounds           |upper_bounds           |key_metadata|split_offsets|equality_ids|\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-39-62ed4a68-19e6-41f6-a476-2d72ae98e813-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> X}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> X}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-38-a3e6dacc-ccfb-40de-bc04-06d763ac52a9-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> P}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> P}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-37-dbbc991b-8622-4fa8-ab6d-56e84f10cf0a-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> G}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> G}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-36-01386018-a642-4800-9417-362cc2c9ac05-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> K}|{1 -> \n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> K}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-35-2a5e6677-f383-4a91-a9b9-9115174ad391-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> M}|{1 -> \u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> M}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-34-f0aac6e7-0727-404f-a7b5-a19522f3d026-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> V}|{1 -> \n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> V}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-33-a83e683c-2b50-4a95-a502-45641492e80e-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> H}|{1 -> \u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> H}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-32-7760e7f0-aa11-4575-8510-8183ebee0428-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0007\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> w}|{1 -> \u0007\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> w}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-31-c3736141-6680-4b18-a149-5484c240c4b7-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \t\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> D}|{1 -> \t\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> D}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-30-33a81f4c-43d2-4434-86c4-33fb8b2cb464-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0007\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> K}|{1 -> \u0007\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> K}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-29-eec4f2ce-1fdf-4df3-bb14-b8c8c88e7539-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> a}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> a}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-28-39edaff8-f6d8-4557-99ac-1c9eb052b7b7-00001.parquet|PARQUET    |1           |621               |{1 -> 45, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> j}|{1 -> \u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> j}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-27-487a17dd-1bb8-42ed-a77d-399185169bc0-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 ->\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> R}|{1 ->\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> R}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-26-9c3d2718-7448-4a40-8898-396e6fd30cfc-00001.parquet|PARQUET    |1           |621               |{1 -> 45, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> P}|{1 -> \u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> P}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-25-a0427165-22a2-497b-843c-60c02d3e5b0a-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> X}|{1 -> \u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> X}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-24-c8bf998d-4027-4489-9672-ca611e767ba5-00001.parquet|PARQUET    |1           |621               |{1 -> 45, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> P}|{1 -> \u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> P}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-23-231f4985-1356-4521-afe8-74e80720f683-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> X}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> X}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-22-e1a762ed-2d5e-41a3-a0cc-e967007b4bc5-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \t\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \t\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-21-f7876fe9-9e83-48d9-8555-1ed848deb10d-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/data/00000-20-7e91fbd5-9578-4c1e-9005-e2c13861f8af-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> k}|{1 -> \u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> k}|null        |[4]          |null        |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable.files\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-brooklyn",
   "metadata": {},
   "source": [
    "### A manifest file is a metadata file that lists a subset of data files that make up a snapshot.\n",
    "\n",
    "### Each data file in a manifest is stored with a partition tuple, column-level stats, and summary information used to prune splits during scan planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-participant",
   "metadata": {},
   "source": [
    "#### To show a table’s file manifests and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "solid-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "|path                                                                                                                               |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|partition_summaries|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/939c9bae-bb1f-4a5e-a792-11c5900a55ab-m0.avro|5599  |0                |7365436161241313619|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/17ad6847-7711-4fcc-bb4f-19c71f1542d5-m0.avro|5598  |0                |4493012414945424199|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/49c9d717-cc74-4bae-a265-09d19281178b-m0.avro|5598  |0                |1164632391803443309|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/db8eee41-ec9c-4ab6-9916-351c503cd272-m0.avro|5595  |0                |3262413394878189407|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/44fed898-ec1a-4293-81e7-e76bae8065a8-m0.avro|5596  |0                |109507450975874535 |1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/79904a14-93c1-44ce-84ac-27fb78d65ced-m0.avro|5598  |0                |3792255592894337398|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/347ef7e2-c65b-435d-91bf-55f804167be4-m0.avro|5598  |0                |3564302959174000179|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/48924224-8f47-4d39-902f-e5d7e47cc5e4-m0.avro|5598  |0                |585031094248925637 |1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/e45cbb89-54d5-4162-94be-07046ea9dfd8-m0.avro|5598  |0                |3220696071393642179|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/7f2574ff-9e4c-4ae3-8425-117d8579478c-m0.avro|5595  |0                |3405255225303221715|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/9a8cb419-8ff0-454f-8517-82303ee76ff8-m0.avro|5597  |0                |6847117683868691402|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/ad654d81-0268-49af-aa60-5da5c78cd7ee-m0.avro|5599  |0                |8804737417880670287|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/ed23c64d-646c-4c62-abe0-471d7fd1bd8e-m0.avro|5598  |0                |3257953117229162659|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/03b5f8ae-ef0e-4449-89e1-02cb9c2a9c6f-m0.avro|5598  |0                |3732764586587101101|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/4449da16-9e4d-4f77-b79e-89b10f31611a-m0.avro|5599  |0                |7509077849794613487|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/74e92b90-5b00-4c6d-ab58-02eb08a02f62-m0.avro|5598  |0                |2796990013176507477|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/99ac8d92-5b38-4aaf-b7c2-0927e86c0221-m0.avro|5597  |0                |7660354957349069526|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/de68f247-2f7b-44db-affe-180d7d474162-m0.avro|5599  |0                |8054197342119973192|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/19ed1951-9697-4b03-8d2d-2ad99ad5ae5b-m0.avro|5598  |0                |6373326086439175233|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/newtesttable/metadata/260795c7-436a-4321-93ca-eb552064d71a-m0.avro|5599  |0                |5868289905218103034|1                     |0                        |0                       |[]                 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable.manifests\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-smith",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-laser",
   "metadata": {},
   "source": [
    "### Using snapshots as shown above, we can insert some data into the table and roll back to its original state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "present-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO spark_catalog.testdb.newtesttable VALUES (1, 'x'), (2, 'y'), (3, 'z')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "faced-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "| 10|   M|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  9|   x|\n",
      "|  6|   u|\n",
      "|  3|   g|\n",
      "|  5|   D|\n",
      "|  9|   D|\n",
      "|  6|   F|\n",
      "|  8|   G|\n",
      "|  8|   Q|\n",
      "|  2|   X|\n",
      "|  6|   R|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  9|   j|\n",
      "|  0|   g|\n",
      "|  0|   i|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using select\n",
    "spark.sql(\"SELECT * FROM spark_catalog.testdb.newtesttable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "useful-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "| 10|   M|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  9|   x|\n",
      "|  6|   u|\n",
      "|  3|   g|\n",
      "|  5|   D|\n",
      "|  9|   D|\n",
      "|  6|   F|\n",
      "|  8|   G|\n",
      "|  8|   Q|\n",
      "|  2|   X|\n",
      "|  6|   R|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  9|   j|\n",
      "|  0|   g|\n",
      "|  0|   i|\n",
      "|  7|   K|\n",
      "| 10|   K|\n",
      "|  5|   p|\n",
      "|  7|   v|\n",
      "|  7|   V|\n",
      "|  5|   M|\n",
      "|  3|   X|\n",
      "|  4|   P|\n",
      "|  8|   y|\n",
      "|  6|   H|\n",
      "|  0|   Y|\n",
      "|  9|   i|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "| 10|   V|\n",
      "|  4|   P|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  6|   z|\n",
      "|  2|   X|\n",
      "|  4|   q|\n",
      "|  0|   Z|\n",
      "|  5|   X|\n",
      "|  7|   w|\n",
      "|  5|   k|\n",
      "|  3|   P|\n",
      "|  0|   K|\n",
      "|  3|   a|\n",
      "|  2|   U|\n",
      "|  8|   R|\n",
      "|  4|   j|\n",
      "|  8|   p|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  2|   G|\n",
      "|  0|   Q|\n",
      "| 10|   e|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  0|   O|\n",
      "|  1|   w|\n",
      "|  7|   v|\n",
      "| 10|   w|\n",
      "|  3|   z|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using DF - All Data\n",
    "df = spark.table(\"spark_catalog.testdb.newtesttable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "subtle-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp = 1653348163.46654\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "timestamp = datetime.timestamp(now)\n",
    "print(\"timestamp =\", timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-commerce",
   "metadata": {},
   "source": [
    "#### Timestamps can be tricky. Please make sure to round your timestamp as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "expanded-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "| 10|   M|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  9|   x|\n",
      "|  6|   u|\n",
      "|  3|   g|\n",
      "|  5|   D|\n",
      "|  9|   D|\n",
      "|  6|   F|\n",
      "|  8|   G|\n",
      "|  8|   Q|\n",
      "|  2|   X|\n",
      "|  6|   R|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  9|   j|\n",
      "|  0|   g|\n",
      "|  0|   i|\n",
      "|  7|   K|\n",
      "| 10|   K|\n",
      "|  5|   p|\n",
      "|  7|   v|\n",
      "|  7|   V|\n",
      "|  5|   M|\n",
      "|  3|   X|\n",
      "|  4|   P|\n",
      "|  8|   y|\n",
      "|  6|   H|\n",
      "|  0|   Y|\n",
      "|  9|   i|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "| 10|   V|\n",
      "|  4|   P|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  6|   z|\n",
      "|  2|   X|\n",
      "|  4|   q|\n",
      "|  0|   Z|\n",
      "|  5|   X|\n",
      "|  7|   w|\n",
      "|  5|   k|\n",
      "|  3|   P|\n",
      "|  0|   K|\n",
      "|  3|   a|\n",
      "|  2|   U|\n",
      "|  8|   R|\n",
      "|  4|   j|\n",
      "|  8|   p|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  2|   G|\n",
      "|  0|   Q|\n",
      "| 10|   e|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  0|   O|\n",
      "|  1|   w|\n",
      "|  7|   v|\n",
      "| 10|   w|\n",
      "|  3|   z|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using a point in time\n",
    "df = spark.read.option(\"as-of-timestamp\", int(timestamp*1000)).format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "parallel-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO spark_catalog.testdb.newtesttable VALUES (1, 'd'), (2, 'e'), (3, 'f')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67832e-4a4c-45f3-b49b-b05bdad33996",
   "metadata": {},
   "source": [
    "### Let's insert more data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3293abf-bb3e-46bd-a993-0a0d10642238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert using Iceberg format\n",
    "import string\n",
    "import random\n",
    "\n",
    "for i in range(25):\n",
    "    number = random.randint(0, 10)\n",
    "    letter = random.choice(string.ascii_letters)\n",
    "    spark.sql(\"INSERT INTO spark_catalog.testdb.newtesttable VALUES ({}, '{}')\".format(number, letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e10c40-d142-4858-85af-4d61996eb3cf",
   "metadata": {},
   "source": [
    "### Now let's access the data again. Let's access it with the same timestemp as before. Notice we have a smaller number of rows than we just inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6dd0858e-93cf-4bbc-97d1-1055cb72bb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "| 10|   M|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  9|   x|\n",
      "|  6|   u|\n",
      "|  3|   g|\n",
      "|  5|   D|\n",
      "|  9|   D|\n",
      "|  6|   F|\n",
      "|  8|   G|\n",
      "|  8|   Q|\n",
      "|  2|   X|\n",
      "|  6|   R|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  9|   j|\n",
      "|  0|   g|\n",
      "|  0|   i|\n",
      "|  7|   K|\n",
      "| 10|   K|\n",
      "|  5|   p|\n",
      "|  7|   v|\n",
      "|  7|   V|\n",
      "|  5|   M|\n",
      "|  3|   X|\n",
      "|  4|   P|\n",
      "|  8|   y|\n",
      "|  6|   H|\n",
      "|  0|   Y|\n",
      "|  9|   i|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "| 10|   V|\n",
      "|  4|   P|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  6|   z|\n",
      "|  2|   X|\n",
      "|  4|   q|\n",
      "|  0|   Z|\n",
      "|  5|   X|\n",
      "|  7|   w|\n",
      "|  5|   k|\n",
      "|  3|   P|\n",
      "|  0|   K|\n",
      "|  3|   a|\n",
      "|  2|   U|\n",
      "|  8|   R|\n",
      "|  4|   j|\n",
      "|  8|   p|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  2|   G|\n",
      "|  0|   Q|\n",
      "| 10|   e|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  0|   O|\n",
      "|  1|   w|\n",
      "|  7|   v|\n",
      "| 10|   w|\n",
      "|  3|   z|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using a point in time\n",
    "df = spark.read.option(\"as-of-timestamp\", int(timestamp*1000)).format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbabc8-ef2e-4fdf-84cd-3cbf40b3391c",
   "metadata": {},
   "source": [
    "### Observe that many new Snapshots have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d35f7a32-7e20-41cd-9793-a963100eeac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2022-05-19 00:27:36.444|5797822168349485877|null               |true               |\n",
      "|2022-05-19 00:28:16.897|3326689113563627160|5797822168349485877|true               |\n",
      "|2022-05-19 00:36:41.604|2080039523045202901|3326689113563627160|true               |\n",
      "|2022-05-19 00:36:42.87 |8726800525946754873|2080039523045202901|true               |\n",
      "|2022-05-19 00:36:43.934|5250560437891035012|8726800525946754873|true               |\n",
      "|2022-05-19 00:36:44.966|3502850421386520639|5250560437891035012|true               |\n",
      "|2022-05-19 00:36:46.076|6484488418513084975|3502850421386520639|true               |\n",
      "|2022-05-19 00:36:47.109|6131843803655349628|6484488418513084975|true               |\n",
      "|2022-05-19 00:36:48.125|9149412625213001646|6131843803655349628|true               |\n",
      "|2022-05-19 00:36:49.154|7899258739660324236|9149412625213001646|true               |\n",
      "|2022-05-19 00:36:50.275|3534193066800053318|7899258739660324236|true               |\n",
      "|2022-05-19 00:36:51.352|1934686370749576161|3534193066800053318|true               |\n",
      "|2022-05-19 00:36:52.394|5426517119305366496|1934686370749576161|true               |\n",
      "|2022-05-19 00:36:53.462|373037863119265479 |5426517119305366496|true               |\n",
      "|2022-05-19 00:36:54.518|5758957638750915040|373037863119265479 |true               |\n",
      "|2022-05-19 00:36:55.545|8456174629502915114|5758957638750915040|true               |\n",
      "|2022-05-19 00:36:56.526|919494437088828330 |8456174629502915114|true               |\n",
      "|2022-05-19 00:36:57.604|8941097323185820492|919494437088828330 |true               |\n",
      "|2022-05-19 00:36:58.628|6624958993800383470|8941097323185820492|true               |\n",
      "|2022-05-19 00:36:59.632|8215457020905462961|6624958993800383470|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.newtesttable.history\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97793e-b86b-4c42-8b85-68397bc44d18",
   "metadata": {},
   "source": [
    "### You can also query the table in its previous state as of a specific partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fd327-6b8a-4bae-8449-1383daaf1bdc",
   "metadata": {},
   "source": [
    "#### Copy paste a partition_id from above and paste it in the next Spark command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e5621db-65e2-47c4-a3a9-e3422b780c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  8|   p|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   w|\n",
      "|  7|   v|\n",
      "|  0|   g|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  7|   v|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read\\\n",
    "    .option(\"snapshot-id\", 6484488418513084975)\\\n",
    "    .table(\"spark_catalog.testdb.newtesttable\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d0f6b-59a5-41f2-ba9b-2e1e8aa0d352",
   "metadata": {},
   "source": [
    "### The Iceberg API allows you to create tables from Spark Dataframes, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0efe36e2-b1cb-47ef-bed4-f902c1e232d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.sql(\"SELECT * FROM spark_catalog.testdb.newtesttable\").sample(fraction=0.5, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3fbcfc09-8874-4dfb-87ad-7bc64d6d7471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'), ('data', 'string')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a3b301e-dfa7-445e-af5a-0d421ad32a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "| 10|   M|\n",
      "|  9|   x|\n",
      "|  6|   u|\n",
      "|  5|   D|\n",
      "|  6|   F|\n",
      "|  6|   R|\n",
      "|  8|   r|\n",
      "|  1|   x|\n",
      "|  9|   j|\n",
      "|  0|   i|\n",
      "| 10|   K|\n",
      "|  5|   p|\n",
      "|  3|   j|\n",
      "|  6|   G|\n",
      "|  7|   V|\n",
      "|  5|   M|\n",
      "|  3|   X|\n",
      "|  6|   O|\n",
      "|  5|   i|\n",
      "|  1|   d|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56beefc7-74e6-4225-8f7d-96f8a891490e",
   "metadata": {},
   "source": [
    "#### Creating a new Spark Table with the API and Loading It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "611cc785-0be4-498d-994b-9aa55a96e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"DROP TABLE IF EXISTS spark_catalog.testdb.secondtesttable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64a36034-a441-4f77-946a-ad182c325a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.writeTo(\"spark_catalog.testdb.secondtesttable\").create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61c443a6-d58c-4392-b5ec-014af794dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_nodups = new_df.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91585a1a-14ab-4ec6-805e-82b4ee5739ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  0|   Z|\n",
      "|  7|   K|\n",
      "|  6|   z|\n",
      "|  9|   x|\n",
      "|  5|   M|\n",
      "|  1|   x|\n",
      "| 10|   e|\n",
      "|  3|   z|\n",
      "|  8|   p|\n",
      "|  2|   y|\n",
      "|  4|   P|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df_nodups.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0c6f3-e3f9-4b31-84ad-84a79575f48d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### More ETL SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7720ee5-a386-4ffb-ade1-0f30201a0f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO spark_catalog.testdb.secondtesttable SELECT * FROM spark_catalog.testdb.newtesttable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c56f9268-a32d-40a6-bec8-21b3f2b20539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7cdc7fb-e201-47d9-843f-b5c84380ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df = spark.sql(\"SELECT * FROM spark_catalog.testdb.secondtesttable\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1156d360-7048-4b73-a80f-5b61b2d39818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3076c279-7650-466f-b62b-a4faf1ca7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df=second_df.withColumn(\"id\", second_df.id*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "369fc391-15b9-4ffe-b3e0-67f39ab76c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df_nodups = second_df.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2570f7d3-1398-4968-8fcd-3774312772e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  0|   g|\n",
      "|  6|   y|\n",
      "|  9|   f|\n",
      "| 27|   x|\n",
      "|  3|   d|\n",
      "| 12|   P|\n",
      "| 18|   u|\n",
      "| 21|   K|\n",
      "| 15|   D|\n",
      "| 30|MMMM|\n",
      "| 24|   G|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sec_df_nodups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05593fc2-5552-4d46-b497-8f3961c4ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_nodups.writeTo(\"spark_catalog.testdb.new_df_nodups\").create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dfef8f70-c37e-40ce-8c43-7f567ce5c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df_nodups.writeTo(\"spark_catalog.testdb.sec_df_nodups\").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788ca58-c278-47b4-8790-948cd84d487e",
   "metadata": {},
   "source": [
    "#### Update and Merge Into SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f059996e-c747-45b1-8640-cada970649fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"UPDATE spark_catalog.testdb.new_df_nodups SET data = '?' WHERE id = (SELECT id FROM spark_catalog.testdb.sec_df_nodups)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8e501-c205-4a24-9b96-13ca9b328fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\n",
    "#\"MERGE INTO spark_catalog.testdb.new_df_nodups t USING (SELECT * FROM spark_catalog.testdb.sec_df_nodups) u ON t.id = u.id \\\n",
    "#WHEN MATCHED THEN UPDATE SET t.data = u.data + t.data \\\n",
    "#WHEN NOT MATCHED THEN INSERT *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865e5f9-0042-4ca6-a12b-15639a72a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT count(*) FROM spark_catalog.testdb.new_df_nodups\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2cd858-6e1d-4026-8648-9307bfef56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM spark_catalog.testdb.new_df_nodups\").show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
